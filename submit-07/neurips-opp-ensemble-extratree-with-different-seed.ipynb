{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":74608,"databundleVersionId":12966160,"sourceType":"competition"},{"sourceId":12189904,"sourceType":"datasetVersion","datasetId":7678100},{"sourceId":12406655,"sourceType":"datasetVersion","datasetId":7824094}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Original Noteboo:\n\nhttps://www.kaggle.com/code/yutongzhang20080108/ensemble-of-extratree-with-different-seeds","metadata":{}},{"cell_type":"markdown","source":"# Import Dependencies ","metadata":{}},{"cell_type":"code","source":"!pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:48:42.638846Z","iopub.execute_input":"2025-07-16T07:48:42.639115Z","iopub.status.idle":"2025-07-16T07:48:49.822389Z","shell.execute_reply.started":"2025-07-16T07:48:42.639088Z","shell.execute_reply":"2025-07-16T07:48:49.821381Z"}},"outputs":[{"name":"stdout","text":"Processing /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (11.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit==2025.3.3) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit==2025.3.3) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit==2025.3.3) (2024.2.0)\nInstalling collected packages: rdkit\nSuccessfully installed rdkit-2025.3.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":" # Importing Required Libraries\\nLet's begin by importing the essential Python libraries needed for data processing, visualization, and modeling.\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\n\nimport networkx as nx\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem import Descriptors\nfrom rdkit.Chem import rdmolops\nfrom rdkit import Chem\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:48:49.824528Z","iopub.execute_input":"2025-07-16T07:48:49.824822Z","iopub.status.idle":"2025-07-16T07:48:51.922896Z","shell.execute_reply.started":"2025-07-16T07:48:49.824796Z","shell.execute_reply":"2025-07-16T07:48:51.922164Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"useless_cols = [   \n    \n    'MaxPartialCharge', \n    # Nan data\n    'BCUT2D_MWHI',\n    'BCUT2D_MWLOW',\n    'BCUT2D_CHGHI',\n    'BCUT2D_CHGLO',\n    'BCUT2D_LOGPHI',\n    'BCUT2D_LOGPLOW',\n    'BCUT2D_MRHI',\n    'BCUT2D_MRLOW',\n\n    # Constant data\n    'NumRadicalElectrons',\n    'SMR_VSA8',\n    'SlogP_VSA9',\n    'fr_barbitur',\n    'fr_benzodiazepine',\n    'fr_dihydropyridine',\n    'fr_epoxide',\n    'fr_isothiocyan',\n    'fr_lactam',\n    'fr_nitroso',\n    'fr_prisulfonamd',\n    'fr_thiocyan',\n\n    # High correlated data >0.95\n    'MaxEStateIndex',\n    'HeavyAtomMolWt',\n    'ExactMolWt',\n    'NumValenceElectrons',\n    'Chi0',\n    'Chi0n',\n    'Chi0v',\n    'Chi1',\n    'Chi1n',\n    'Chi1v',\n    'Chi2n',\n    'Kappa1',\n    'LabuteASA',\n    'HeavyAtomCount',\n    'MolMR',\n    'Chi3n',\n    'BertzCT',\n    'Chi2v',\n    'Chi4n',\n    'HallKierAlpha',\n    'Chi3v',\n    'Chi4v',\n    'MinAbsPartialCharge',\n    'MinPartialCharge',\n    'MaxAbsPartialCharge',\n    'FpDensityMorgan2',\n    'FpDensityMorgan3',\n    'Phi',\n    'Kappa3',\n    'fr_nitrile',\n    'SlogP_VSA6',\n    'NumAromaticCarbocycles',\n    'NumAromaticRings',\n    'fr_benzene',\n    'VSA_EState6',\n    'NOCount',\n    'fr_C_O',\n    'fr_C_O_noCOO',\n    'NumHDonors',\n    'fr_amide',\n    'fr_Nhpyrrole',\n    'fr_phenol',\n    'fr_phenol_noOrthoHbond',\n    'fr_COO2',\n    'fr_halogen',\n    'fr_diazo',\n    'fr_nitro_arom',\n    'fr_phos_ester'\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:48:51.923748Z","iopub.execute_input":"2025-07-16T07:48:51.924322Z","iopub.status.idle":"2025-07-16T07:48:51.931593Z","shell.execute_reply.started":"2025-07-16T07:48:51.924292Z","shell.execute_reply":"2025-07-16T07:48:51.930853Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Read Files","metadata":{}},{"cell_type":"code","source":"tg=pd.read_csv('/kaggle/input/neurips-dataset/tg.csv')\nrg=pd.read_csv('/kaggle/input/neurips-dataset/rg.csv')\ntc=pd.read_csv('/kaggle/input/neurips-dataset/tc.csv')\nffv=pd.read_csv('/kaggle/input/neurips-dataset/ffv.csv')\ndensity=pd.read_csv('/kaggle/input/neurips-dataset/density.csv')\ntest=pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')\nID=test['id'].copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:48:51.932648Z","iopub.execute_input":"2025-07-16T07:48:51.933031Z","iopub.status.idle":"2025-07-16T07:48:52.363625Z","shell.execute_reply.started":"2025-07-16T07:48:51.932997Z","shell.execute_reply":"2025-07-16T07:48:52.362956Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Preprocessing ","metadata":{}},{"cell_type":"code","source":"def make_smile_canonical(smile): # To avoid duplicates, for example: canonical '*C=C(*)C' == '*C(=C*)C'\n    try:\n        mol = Chem.MolFromSmiles(smile)\n        canon_smile = Chem.MolToSmiles(mol, canonical=True)\n        return canon_smile\n    except:\n        return np.nan\ntest['SMILES'] = test['SMILES'].apply(lambda s: make_smile_canonical(s))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:48:52.364442Z","iopub.execute_input":"2025-07-16T07:48:52.364670Z","iopub.status.idle":"2025-07-16T07:48:52.372835Z","shell.execute_reply.started":"2025-07-16T07:48:52.364652Z","shell.execute_reply":"2025-07-16T07:48:52.372057Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def preprocessing(df):\n    desc_names = [desc[0] for desc in Descriptors.descList if desc[0] not in useless_cols]\n    descriptors = [compute_all_descriptors(smi) for smi in df['SMILES'].to_list()]\n\n    graph_feats = {'graph_diameter': [], 'avg_shortest_path': [], 'num_cycles': []}\n    for smile in df['SMILES']:\n         compute_graph_features(smile, graph_feats)\n        \n    result = pd.concat(\n        [\n            pd.DataFrame(descriptors, columns=desc_names),\n            pd.DataFrame(graph_feats)\n        ],\n        axis=1\n    )\n\n    result = result.replace([-np.inf, np.inf], np.nan)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:48:52.373580Z","iopub.execute_input":"2025-07-16T07:48:52.373783Z","iopub.status.idle":"2025-07-16T07:48:52.392333Z","shell.execute_reply.started":"2025-07-16T07:48:52.373766Z","shell.execute_reply":"2025-07-16T07:48:52.391571Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Feature Extraction ","metadata":{}},{"cell_type":"code","source":"def compute_all_descriptors(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return [None] * len(desc_names)\n    return [desc[1](mol) for desc in Descriptors.descList if desc[0] not in useless_cols]\n\ndef compute_graph_features(smiles, graph_feats):\n    mol = Chem.MolFromSmiles(smiles)\n    adj = rdmolops.GetAdjacencyMatrix(mol)\n    G = nx.from_numpy_array(adj)\n\n    graph_feats['graph_diameter'].append(nx.diameter(G) if nx.is_connected(G) else 0)\n    graph_feats['avg_shortest_path'].append(nx.average_shortest_path_length(G) if nx.is_connected(G) else 0)\n    graph_feats['num_cycles'].append(len(list(nx.cycle_basis(G))))\n\ntest = pd.concat([test, preprocessing(test)], axis=1)\ntest['Ipc']=np.log10(test['Ipc'])\n\ntest=test.drop(['id','SMILES'],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:48:52.395114Z","iopub.execute_input":"2025-07-16T07:48:52.395403Z","iopub.status.idle":"2025-07-16T07:48:52.516592Z","shell.execute_reply.started":"2025-07-16T07:48:52.395385Z","shell.execute_reply":"2025-07-16T07:48:52.515933Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Model ","metadata":{}},{"cell_type":"code","source":"# Letâ€™s define a reusable function to train and evaluate our machine learning model.\n\ndef model_seed_1(train_d,test_d,model,target,submission=False):\n    # We divide the data into training and validation sets for model evaluation\n    X=train_d.drop(target,axis=1)\n    y=train_d[target].copy()\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n    Model=model(random_state=21)\n    if submission==False:\n       Model.fit(X_train,y_train)\n       y_pred=Model.predict(X_test)\n       return mean_absolute_error(y_pred,y_test)         # We assess our model performance using MAE metric\n    if submission==True:\n       Model.fit(X,y)\n       submission=Model.predict(test_d)\n       return submission\ndef model_seed_2(train_d,test_d,model,target,submission=False):\n    # We divide the data into training and validation sets for model evaluation\n    X=train_d.drop(target,axis=1)\n    y=train_d[target].copy()\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n    Model=model(random_state=42)\n    if submission==False:\n       Model.fit(X_train,y_train)\n       y_pred=Model.predict(X_test)\n       return mean_absolute_error(y_pred,y_test)         # We assess our model performance using MAE metric\n    if submission==True:\n       Model.fit(X,y)\n       submission=Model.predict(test_d)\n       return submission \ndef model_seed_3(train_d,test_d,model,target,submission=False):\n    # We divide the data into training and validation sets for model evaluation\n    X=train_d.drop(target,axis=1)\n    y=train_d[target].copy()\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n    Model=model(random_state=100)\n    if submission==False:\n       Model.fit(X_train,y_train)\n       y_pred=Model.predict(X_test)\n       return mean_absolute_error(y_pred,y_test)         # We assess our model performance using MAE metric\n    if submission==True:\n       Model.fit(X,y)\n       submission=Model.predict(test_d)\n       return submission \ndef model_seed_4(train_d,test_d,model,target,submission=False):\n    # We divide the data into training and validation sets for model evaluation\n    X=train_d.drop(target,axis=1)\n    y=train_d[target].copy()\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n    Model=model(random_state=456)\n    if submission==False:\n       Model.fit(X_train,y_train)\n       y_pred=Model.predict(X_test)\n       return mean_absolute_error(y_pred,y_test)         # We assess our model performance using MAE metric\n    if submission==True:\n       Model.fit(X,y)\n       submission=Model.predict(test_d)\n       return submission \ndef model_seed_5(train_d,test_d,model,target,submission=False):\n    # We divide the data into training and validation sets for model evaluation\n    X=train_d.drop(target,axis=1)\n    y=train_d[target].copy()\n    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)\n\n    Model=model(random_state=666)\n    if submission==False:\n       Model.fit(X_train,y_train)\n       y_pred=Model.predict(X_test)\n       return mean_absolute_error(y_pred,y_test)         # We assess our model performance using MAE metric\n    if submission==True:\n       Model.fit(X,y)\n       submission=Model.predict(test_d)\n       return submission ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:48:52.517389Z","iopub.execute_input":"2025-07-16T07:48:52.517644Z","iopub.status.idle":"2025-07-16T07:48:52.530483Z","shell.execute_reply.started":"2025-07-16T07:48:52.517625Z","shell.execute_reply":"2025-07-16T07:48:52.529736Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"# Final Model For Submission","metadata":{}},{"cell_type":"code","source":"# Average predictions from 5 model seeds for each target\ntg_result = (\n    model_seed_1(tg, test, ExtraTreesRegressor, 'Tg', submission=True) +\n    model_seed_2(tg, test, ExtraTreesRegressor, 'Tg', submission=True) +\n    model_seed_3(tg, test, ExtraTreesRegressor, 'Tg', submission=True) +\n    model_seed_4(tg, test, ExtraTreesRegressor, 'Tg', submission=True) +\n    model_seed_5(tg, test, ExtraTreesRegressor, 'Tg', submission=True)\n) / 5\n\nffv_result = (\n    model_seed_1(ffv, test, ExtraTreesRegressor, 'FFV', submission=True) +\n    model_seed_2(ffv, test, ExtraTreesRegressor, 'FFV', submission=True) +\n    model_seed_3(ffv, test, ExtraTreesRegressor, 'FFV', submission=True) +\n    model_seed_4(ffv, test, ExtraTreesRegressor, 'FFV', submission=True) +\n    model_seed_5(ffv, test, ExtraTreesRegressor, 'FFV', submission=True)\n) / 5\n\ntc_result = (\n    model_seed_1(tc, test, ExtraTreesRegressor, 'Tc', submission=True) +\n    model_seed_2(tc, test, ExtraTreesRegressor, 'Tc', submission=True) +\n    model_seed_3(tc, test, ExtraTreesRegressor, 'Tc', submission=True) +\n    model_seed_4(tc, test, ExtraTreesRegressor, 'Tc', submission=True) +\n    model_seed_5(tc, test, ExtraTreesRegressor, 'Tc', submission=True)\n) / 5\n\ndensity_result = (\n    model_seed_1(density, test, ExtraTreesRegressor, 'Density', submission=True) +\n    model_seed_2(density, test, ExtraTreesRegressor, 'Density', submission=True) +\n    model_seed_3(density, test, ExtraTreesRegressor, 'Density', submission=True) +\n    model_seed_4(density, test, ExtraTreesRegressor, 'Density', submission=True) +\n    model_seed_5(density, test, ExtraTreesRegressor, 'Density', submission=True)\n) / 5\n\nrg_result = (\n    model_seed_1(rg, test, ExtraTreesRegressor, 'Rg', submission=True) +\n    model_seed_2(rg, test, ExtraTreesRegressor, 'Rg', submission=True) +\n    model_seed_3(rg, test, ExtraTreesRegressor, 'Rg', submission=True) +\n    model_seed_4(rg, test, ExtraTreesRegressor, 'Rg', submission=True) +\n    model_seed_5(rg, test, ExtraTreesRegressor, 'Rg', submission=True)\n) / 5\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:48:52.531360Z","iopub.execute_input":"2025-07-16T07:48:52.531832Z","iopub.status.idle":"2025-07-16T07:50:40.890865Z","shell.execute_reply.started":"2025-07-16T07:48:52.531805Z","shell.execute_reply":"2025-07-16T07:50:40.890120Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":" # Finally, we use the model to predict on the test set and prepare the submission file.\n\nsub={'id':ID,'Tg':tg_result,\n     'FFV':ffv_result,\n     'Tc':tc_result,\n     'Density':density_result,\n     'Rg':rg_result}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:50:40.891663Z","iopub.execute_input":"2025-07-16T07:50:40.891913Z","iopub.status.idle":"2025-07-16T07:50:40.896685Z","shell.execute_reply.started":"2025-07-16T07:50:40.891896Z","shell.execute_reply":"2025-07-16T07:50:40.895721Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"submission=pd.DataFrame(sub)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:50:40.897606Z","iopub.execute_input":"2025-07-16T07:50:40.898633Z","iopub.status.idle":"2025-07-16T07:50:40.914732Z","shell.execute_reply.started":"2025-07-16T07:50:40.898609Z","shell.execute_reply":"2025-07-16T07:50:40.913822Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:50:40.915901Z","iopub.execute_input":"2025-07-16T07:50:40.916239Z","iopub.status.idle":"2025-07-16T07:50:40.947857Z","shell.execute_reply.started":"2025-07-16T07:50:40.916205Z","shell.execute_reply":"2025-07-16T07:50:40.946951Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"           id          Tg       FFV        Tc   Density         Rg\n0  1109053969  159.367858  0.372830  0.183653  1.145713  20.429810\n1  1422188626  163.984013  0.374475  0.235749  1.112386  19.758896\n2  2032016830   95.520068  0.350464  0.268780  1.085902  20.639774","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Tg</th>\n      <th>FFV</th>\n      <th>Tc</th>\n      <th>Density</th>\n      <th>Rg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1109053969</td>\n      <td>159.367858</td>\n      <td>0.372830</td>\n      <td>0.183653</td>\n      <td>1.145713</td>\n      <td>20.429810</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1422188626</td>\n      <td>163.984013</td>\n      <td>0.374475</td>\n      <td>0.235749</td>\n      <td>1.112386</td>\n      <td>19.758896</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2032016830</td>\n      <td>95.520068</td>\n      <td>0.350464</td>\n      <td>0.268780</td>\n      <td>1.085902</td>\n      <td>20.639774</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-16T07:50:40.948670Z","iopub.execute_input":"2025-07-16T07:50:40.948978Z","iopub.status.idle":"2025-07-16T07:50:40.959211Z","shell.execute_reply.started":"2025-07-16T07:50:40.948949Z","shell.execute_reply":"2025-07-16T07:50:40.958361Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"Result:\n\nScore: \n\nRank: \n\nRuntime: 5min (Kaggle editor)\n\nYour Best Entry!\nYour most recent submission scored 0.032, which is an improvement of your previous score of 0.033. Great job!\n\nMoving up to rank 73. rising like my electricity bill. #kaggle - https://kaggle.com/competitions/neurips-open-polymer-prediction-2025 ","metadata":{}}]}