{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":74608,"databundleVersionId":12609125,"sourceType":"competition"},{"sourceId":12191182,"sourceType":"datasetVersion","datasetId":7678913},{"sourceId":12206965,"sourceType":"datasetVersion","datasetId":7689713},{"sourceId":12207625,"sourceType":"datasetVersion","datasetId":7690162},{"sourceId":246274448,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Original NotoBook: \n\nhttps://www.kaggle.com/code/richolson/smiles-rdkit-lgbm-ftw","metadata":{}},{"cell_type":"markdown","source":"# SMILES->RDKIT->LGBM->FTW  🧪⚡🚀\n\n**SMILES** *(Simplified Molecular Input Line Entry System)*  \n**RDKIT** *(Open-source cheminformatics toolkit)*   \n**LGBM** *(Light Gradient Boosting Machine)*  \n**FTW** *(For The Win!)*  \n\n## 1. Use RDKit to calculate *chemical descriptors* from our SMILES molecule data\n- **Structural Counts:** Ring counts, rotatable bonds, molecular weight\n- **Calculated Properties:** LogP (oiliness), TPSA (surface area), qed (drug-likeness), complexity/shape stuff\n- We infer these for both **train** and **test** data\n- **We are using RDKit to do feature engineering**\n\n## 2. Train models using those features to predict our *targets*:\n- **Tg** - Glass transition temperature (°C)\n- **FFV** - Fractional free volume\n- **Tc** - Thermal conductivity (W/m·K)\n- **Density** - Polymer density (g/cm³)\n- **Rg** - Radius of gyration (Å)\n\n## 3. Estimate LB Score\n- We import a copy of the competition metric: https://www.kaggle.com/code/metric/open-polymer-2025\n- Use it to make a guess at how we will rank on the LB\n- Likely a bit optimistic since we choose boosting round (epoch) based on best score\n\n## We train unique LGBM models for each target!\n- Actually 5 models per target using CV / averaging predictions (**25 models total!**)\n- **RDKit is doing the heavy-lifting here** - we just train an LGBM model to figure out how to translate the data to our targets...\n\n### *Friendly Reminder:* If re-using large parts of this work in a public notebook - **please credit where you found the code**","metadata":{"_kg_hide-output":true}},{"cell_type":"markdown","source":"## *Now with extra training data for Tg and Tc!*\n\nOut of the 5 targets - only FFV is well represented in the training data.\n\nWe use these datasets to help fill things in for Tg and Tc:\n* https://www.kaggle.com/datasets/minatoyukinaxlisa/smiles-tg\n* https://www.kaggle.com/datasets/minatoyukinaxlisa/tc-smiles\n\nSource information:\n* https://github.com/Jiaxin-Xu/POINT2/blob/main/data/labeled/polyinfo/Tg_SMILES_class_pid_polyinfo_median.csv\n* https://github.com/Jiaxin-Xu/POINT2/blob/main/data/labeled/nd/TC_MD_20240306.xlsx\n* https://www.kaggle.com/competitions/neurips-open-polymer-prediction-2025/discussion/585178","metadata":{}},{"cell_type":"markdown","source":"# Install RDKit\n* https://www.kaggle.com/datasets/richolson/rdkit-install-whl","metadata":{}},{"cell_type":"code","source":"# install RDKit for offline use\n!pip install /kaggle/input/rdkit-install-whl/rdkit_wheel/rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:11:25.865031Z","iopub.execute_input":"2025-06-20T16:11:25.865329Z","iopub.status.idle":"2025-06-20T16:11:34.548327Z","shell.execute_reply.started":"2025-06-20T16:11:25.865305Z","shell.execute_reply":"2025-06-20T16:11:34.547034Z"}},"outputs":[{"name":"stdout","text":"Processing /kaggle/input/rdkit-install-whl/rdkit_wheel/rdkit_pypi-2022.9.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi==2022.9.5) (1.26.4)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit-pypi==2022.9.5) (11.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi==2022.9.5) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi==2022.9.5) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi==2022.9.5) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi==2022.9.5) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi==2022.9.5) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit-pypi==2022.9.5) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi==2022.9.5) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit-pypi==2022.9.5) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit-pypi==2022.9.5) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit-pypi==2022.9.5) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit-pypi==2022.9.5) (2024.2.0)\nInstalling collected packages: rdkit-pypi\nSuccessfully installed rdkit-pypi-2022.9.5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors, rdMolDescriptors\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_absolute_error\nimport lightgbm as lgb\nimport warnings\n\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-06-20T16:11:34.550746Z","iopub.execute_input":"2025-06-20T16:11:34.551250Z","iopub.status.idle":"2025-06-20T16:11:41.295356Z","shell.execute_reply.started":"2025-06-20T16:11:34.551206Z","shell.execute_reply":"2025-06-20T16:11:41.294348Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Simple SMILES / RDKit Demo\n* So you can see how this works...","metadata":{}},{"cell_type":"code","source":"molecules = [\n    ('CCO', 'Ethanol - simple alcohol'),\n    ('CCCCCCCC', 'Octane - long chain'),\n    ('c1ccccc1', 'Benzene - aromatic ring'),\n]\n\nfor smiles, description in molecules:\n    mol = Chem.MolFromSmiles(smiles)\n    \n    print(f\"\\n{description}\")\n    print(f\"SMILES: {smiles}\")\n    print(f\"  Molecular Weight: {Descriptors.MolWt(mol):.1f}\")\n    print(f\"  LogP (oiliness): {Descriptors.MolLogP(mol):.2f}\")\n    print(f\"  Rotatable Bonds: {Descriptors.NumRotatableBonds(mol)}\")\n    print(f\"  Aromatic Rings: {Descriptors.NumAromaticRings(mol)}\")\n    print(f\"  Complexity (BertzCT): {Descriptors.BertzCT(mol):.0f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:11:41.296294Z","iopub.execute_input":"2025-06-20T16:11:41.296832Z","iopub.status.idle":"2025-06-20T16:11:41.310024Z","shell.execute_reply.started":"2025-06-20T16:11:41.296806Z","shell.execute_reply":"2025-06-20T16:11:41.308801Z"}},"outputs":[{"name":"stdout","text":"\nEthanol - simple alcohol\nSMILES: CCO\n  Molecular Weight: 46.1\n  LogP (oiliness): -0.00\n  Rotatable Bonds: 0\n  Aromatic Rings: 0\n  Complexity (BertzCT): 3\n\nOctane - long chain\nSMILES: CCCCCCCC\n  Molecular Weight: 114.2\n  LogP (oiliness): 3.37\n  Rotatable Bonds: 5\n  Aromatic Rings: 0\n  Complexity (BertzCT): 25\n\nBenzene - aromatic ring\nSMILES: c1ccccc1\n  Molecular Weight: 78.1\n  LogP (oiliness): 1.69\n  Rotatable Bonds: 0\n  Aromatic Rings: 1\n  Complexity (BertzCT): 72\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Load Train Data","metadata":{}},{"cell_type":"code","source":"# Load data\ncomp_train_df = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/train.csv')\ncomp_train_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:11:41.313017Z","iopub.execute_input":"2025-06-20T16:11:41.313759Z","iopub.status.idle":"2025-06-20T16:11:41.400719Z","shell.execute_reply.started":"2025-06-20T16:11:41.313722Z","shell.execute_reply":"2025-06-20T16:11:41.399232Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       id                                             SMILES  Tg       FFV  \\\n0   87817                         *CC(*)c1ccccc1C(=O)OCCCCCC NaN  0.374645   \n1  106919  *Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5... NaN  0.370410   \n2  388772  *Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(... NaN  0.378860   \n\n         Tc  Density  Rg  \n0  0.205667      NaN NaN  \n1       NaN      NaN NaN  \n2       NaN      NaN NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>SMILES</th>\n      <th>Tg</th>\n      <th>FFV</th>\n      <th>Tc</th>\n      <th>Density</th>\n      <th>Rg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>87817</td>\n      <td>*CC(*)c1ccccc1C(=O)OCCCCCC</td>\n      <td>NaN</td>\n      <td>0.374645</td>\n      <td>0.205667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106919</td>\n      <td>*Nc1ccc([C@H](CCC)c2ccc(C3(c4ccc([C@@H](CCC)c5...</td>\n      <td>NaN</td>\n      <td>0.370410</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>388772</td>\n      <td>*Oc1ccc(S(=O)(=O)c2ccc(Oc3ccc(C4(c5ccc(Oc6ccc(...</td>\n      <td>NaN</td>\n      <td>0.378860</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Define Targets / Check Counts\n* Only FFV is well represented in train...","metadata":{}},{"cell_type":"code","source":"# Define all target properties\ntargets = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n\n# Count of non-NaN values for each target column\ncomp_train_df[targets].count()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:11:41.402074Z","iopub.execute_input":"2025-06-20T16:11:41.402368Z","iopub.status.idle":"2025-06-20T16:11:41.420002Z","shell.execute_reply.started":"2025-06-20T16:11:41.402347Z","shell.execute_reply":"2025-06-20T16:11:41.419006Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Tg          511\nFFV        7030\nTc          737\nDensity     613\nRg          614\ndtype: int64"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Look at our additional Tg and Tc data","metadata":{}},{"cell_type":"code","source":"extra_tg_df = pd.read_csv('/kaggle/input/smiles-tg/Tg_SMILES_class_pid_polyinfo_median.csv')\ndisplay(extra_tg_df.head(3))\n\nextra_tc_df = pd.read_csv('/kaggle/input/tc-smiles/Tc_SMILES.csv')\ndisplay(extra_tc_df.head(3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:11:41.421480Z","iopub.execute_input":"2025-06-20T16:11:41.421848Z","iopub.status.idle":"2025-06-20T16:11:41.492334Z","shell.execute_reply.started":"2025-06-20T16:11:41.421814Z","shell.execute_reply":"2025-06-20T16:11:41.491082Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"     SMILES      PID Polymer Class    Tg\n0       *C*  P010001   Polyolefins -54.0\n1   *CC(*)C  P010002   Polyolefins  -3.0\n2  *CC(*)CC  P010003   Polyolefins -24.1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SMILES</th>\n      <th>PID</th>\n      <th>Polymer Class</th>\n      <th>Tg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>*C*</td>\n      <td>P010001</td>\n      <td>Polyolefins</td>\n      <td>-54.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>*CC(*)C</td>\n      <td>P010002</td>\n      <td>Polyolefins</td>\n      <td>-3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>*CC(*)CC</td>\n      <td>P010003</td>\n      <td>Polyolefins</td>\n      <td>-24.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"    TC_mean     SMILES\n0  0.244500    *CC(*)C\n1  0.225333   *CC(*)CC\n2  0.246333  *CC(*)CCC","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TC_mean</th>\n      <th>SMILES</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.244500</td>\n      <td>*CC(*)C</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.225333</td>\n      <td>*CC(*)CC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.246333</td>\n      <td>*CC(*)CCC</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"# Merge Tg and Tc Data with Competition Train Data\n* Needs a little reformatting...\n* Look at the target counts - that's more like it!","metadata":{}},{"cell_type":"code","source":"# Prepare extra_tg_df\nextra_tg_clean = extra_tg_df[['SMILES', 'PID', 'Tg']].rename(columns={'PID': 'id'})\nextra_tg_clean[['FFV', 'Tc', 'Density', 'Rg']] = float('nan')\n\n# Prepare extra_tc_df  \nextra_tc_clean = extra_tc_df[['SMILES', 'TC_mean']].rename(columns={'TC_mean': 'Tc'})\nextra_tc_clean['id'] = range(len(comp_train_df) + len(extra_tg_df), len(comp_train_df) + len(extra_tg_df) + len(extra_tc_df))\nextra_tc_clean[['Tg', 'FFV', 'Density', 'Rg']] = float('nan')\n\n# Reorder columns to match train_df\nextra_tg_clean = extra_tg_clean[['id', 'SMILES', 'Tg', 'FFV', 'Tc', 'Density', 'Rg']]\nextra_tc_clean = extra_tc_clean[['id', 'SMILES', 'Tg', 'FFV', 'Tc', 'Density', 'Rg']]\n\n# Combine all datasets into train_df\ntrain_df = pd.concat([comp_train_df, extra_tg_clean, extra_tc_clean], ignore_index=True)\n\nprint(train_df[targets].count())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:11:41.493599Z","iopub.execute_input":"2025-06-20T16:11:41.494622Z","iopub.status.idle":"2025-06-20T16:11:41.523765Z","shell.execute_reply.started":"2025-06-20T16:11:41.494585Z","shell.execute_reply":"2025-06-20T16:11:41.522102Z"}},"outputs":[{"name":"stdout","text":"Tg         7719\nFFV        7030\nTc         1611\nDensity     613\nRg          614\ndtype: int64\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Define molecular descriptions to be generated by RDKit\n* These are properties that RDKit can determine based on SMILES data\n* Auto-discovers 400 descriptors defined by RDKit\n* Only uses a subset of 192 AUTOCORR2D descriptors (as defined by max_autocorr) \n* We develop models to take this information and predict our actual targets  ('Tg', 'FFV', 'Tc', 'Density', 'Rg')","metadata":{}},{"cell_type":"code","source":"def get_molecular_descriptors(max_autocorr=10):\n    \"\"\"Get molecular descriptors - either hardcoded list or auto-discovered\"\"\"\n\n    descriptor_list_all = []\n    test_mol = Chem.MolFromSmiles('CCO')\n\n    # Collect all valid descriptors first\n    for name in dir(Descriptors):\n        if not name.startswith('_'):\n            try:\n                func = getattr(Descriptors, name)\n                if callable(func):\n                    result = func(test_mol)\n                    if isinstance(result, (int, float)) and not np.isnan(result):\n                        descriptor_list_all.append((name, func))\n            except:\n                pass\n\n    print(f\"🔍 Total discovered descriptors before filtering: {len(descriptor_list_all)}\")\n\n    # Sort AUTOCORR2D descriptors by their numeric suffix\n    autocorr_descriptors = [\n        (name, func)\n        for name, func in descriptor_list_all\n        if name.startswith('AUTOCORR2D_')\n    ]\n    autocorr_descriptors.sort(key=lambda x: int(x[0].split('_')[-1]))\n\n    # Select only the lowest-numbered ones\n    limited_autocorr = autocorr_descriptors[:max_autocorr]\n\n    # Include all other descriptors\n    other_descriptors = [\n        (name, func)\n        for name, func in descriptor_list_all\n        if not name.startswith('AUTOCORR2D_')\n    ]\n\n    # Final descriptor list\n    descriptor_list = limited_autocorr + other_descriptors\n\n    print(f\"✅ Auto-discovered {len(descriptor_list)} descriptors (limited to {max_autocorr} AUTOCORR2D):\")\n    names = [name for name, _ in descriptor_list]\n    print(\"  \" + \", \".join(names))\n\n    feature_names = [name for name, _ in descriptor_list]\n    return descriptor_list, feature_names\n\nmolecular_descriptors =  get_molecular_descriptors(max_autocorr=10) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:11:41.525039Z","iopub.execute_input":"2025-06-20T16:11:41.525350Z","iopub.status.idle":"2025-06-20T16:11:41.556607Z","shell.execute_reply.started":"2025-06-20T16:11:41.525318Z","shell.execute_reply":"2025-06-20T16:11:41.555498Z"}},"outputs":[{"name":"stdout","text":"🔍 Total discovered descriptors before filtering: 400\n✅ Auto-discovered 218 descriptors (limited to 10 AUTOCORR2D):\n  AUTOCORR2D_1, AUTOCORR2D_2, AUTOCORR2D_3, AUTOCORR2D_4, AUTOCORR2D_5, AUTOCORR2D_6, AUTOCORR2D_7, AUTOCORR2D_8, AUTOCORR2D_9, AUTOCORR2D_10, BCUT2D_CHGHI, BCUT2D_CHGLO, BCUT2D_LOGPHI, BCUT2D_LOGPLOW, BCUT2D_MRHI, BCUT2D_MRLOW, BCUT2D_MWHI, BCUT2D_MWLOW, BalabanJ, BertzCT, Chi0, Chi0n, Chi0v, Chi1, Chi1n, Chi1v, Chi2n, Chi2v, Chi3n, Chi3v, Chi4n, Chi4v, EState_VSA1, EState_VSA10, EState_VSA11, EState_VSA2, EState_VSA3, EState_VSA4, EState_VSA5, EState_VSA6, EState_VSA7, EState_VSA8, EState_VSA9, ExactMolWt, FpDensityMorgan1, FpDensityMorgan2, FpDensityMorgan3, FractionCSP3, HallKierAlpha, HeavyAtomCount, HeavyAtomMolWt, Ipc, Kappa1, Kappa2, Kappa3, LabuteASA, MaxAbsEStateIndex, MaxAbsPartialCharge, MaxEStateIndex, MaxPartialCharge, MinAbsEStateIndex, MinAbsPartialCharge, MinEStateIndex, MinPartialCharge, MolLogP, MolMR, MolWt, NHOHCount, NOCount, NumAliphaticCarbocycles, NumAliphaticHeterocycles, NumAliphaticRings, NumAromaticCarbocycles, NumAromaticHeterocycles, NumAromaticRings, NumHAcceptors, NumHDonors, NumHeteroatoms, NumRadicalElectrons, NumRotatableBonds, NumSaturatedCarbocycles, NumSaturatedHeterocycles, NumSaturatedRings, NumValenceElectrons, PEOE_VSA1, PEOE_VSA10, PEOE_VSA11, PEOE_VSA12, PEOE_VSA13, PEOE_VSA14, PEOE_VSA2, PEOE_VSA3, PEOE_VSA4, PEOE_VSA5, PEOE_VSA6, PEOE_VSA7, PEOE_VSA8, PEOE_VSA9, RingCount, SMR_VSA1, SMR_VSA10, SMR_VSA2, SMR_VSA3, SMR_VSA4, SMR_VSA5, SMR_VSA6, SMR_VSA7, SMR_VSA8, SMR_VSA9, SlogP_VSA1, SlogP_VSA10, SlogP_VSA11, SlogP_VSA12, SlogP_VSA2, SlogP_VSA3, SlogP_VSA4, SlogP_VSA5, SlogP_VSA6, SlogP_VSA7, SlogP_VSA8, SlogP_VSA9, TPSA, VSA_EState1, VSA_EState10, VSA_EState2, VSA_EState3, VSA_EState4, VSA_EState5, VSA_EState6, VSA_EState7, VSA_EState8, VSA_EState9, fr_Al_COO, fr_Al_OH, fr_Al_OH_noTert, fr_ArN, fr_Ar_COO, fr_Ar_N, fr_Ar_NH, fr_Ar_OH, fr_COO, fr_COO2, fr_C_O, fr_C_O_noCOO, fr_C_S, fr_HOCCN, fr_Imine, fr_NH0, fr_NH1, fr_NH2, fr_N_O, fr_Ndealkylation1, fr_Ndealkylation2, fr_Nhpyrrole, fr_SH, fr_aldehyde, fr_alkyl_carbamate, fr_alkyl_halide, fr_allylic_oxid, fr_amide, fr_amidine, fr_aniline, fr_aryl_methyl, fr_azide, fr_azo, fr_barbitur, fr_benzene, fr_benzodiazepine, fr_bicyclic, fr_diazo, fr_dihydropyridine, fr_epoxide, fr_ester, fr_ether, fr_furan, fr_guanido, fr_halogen, fr_hdrzine, fr_hdrzone, fr_imidazole, fr_imide, fr_isocyan, fr_isothiocyan, fr_ketone, fr_ketone_Topliss, fr_lactam, fr_lactone, fr_methoxy, fr_morpholine, fr_nitrile, fr_nitro, fr_nitro_arom, fr_nitro_arom_nonortho, fr_nitroso, fr_oxazole, fr_oxime, fr_para_hydroxylation, fr_phenol, fr_phenol_noOrthoHbond, fr_phos_acid, fr_phos_ester, fr_piperdine, fr_piperzine, fr_priamide, fr_prisulfonamd, fr_pyridine, fr_quatN, fr_sulfide, fr_sulfonamd, fr_sulfone, fr_term_acetylene, fr_tetrazole, fr_thiazole, fr_thiocyan, fr_thiophene, fr_unbrch_alkane, fr_urea, qed\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Run RDKit on SMILES Train data\n* Predicts molecular descriptors we previously defined\n* This is time intensive - so we do it once here instead of in training loop\n* This function is also used to process Test data later","metadata":{}},{"cell_type":"code","source":"def smiles_to_features(smiles_list, descriptor_functions):\n   \"\"\"Convert SMILES strings to raw feature matrix\"\"\"\n   \n   features = []\n   total = len(smiles_list)\n   \n   print(f\"Processing {total} SMILES...\", end=\"\", flush=True)\n   \n   for i, smiles in enumerate(smiles_list):\n       # Progress indicator every 1000 molecules or at milestones\n       if i > 0 and (i % 1000 == 0 or i == total - 1):\n           print(f\" {i+1}/{total}\", end=\"\", flush=True)\n       \n       mol_features = []\n       try:\n           mol = Chem.MolFromSmiles(smiles)\n           if mol is None:\n               # Invalid SMILES - fill with NaN\n               mol_features = [np.nan] * len(descriptor_functions)\n           else:\n               # Calculate each descriptor\n               for name, func in descriptor_functions:\n                   try:\n                       value = func(mol)\n                       # Handle problematic values\n                       if np.isinf(value) or abs(value) > 1e10:\n                           value = np.nan\n                       mol_features.append(value)\n                   except:\n                       # Descriptor calculation failed\n                       mol_features.append(np.nan)\n       except:\n           # Complete failure - fill entire row with NaN\n           mol_features = [np.nan] * len(descriptor_functions)\n       \n       features.append(mol_features)\n   \n   print(\" ✅\", flush=True)\n   return np.array(features, dtype=float)\n\ndescriptor_functions, feature_names = molecular_descriptors\nX_raw = smiles_to_features(train_df['SMILES'].values, descriptor_functions)    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:11:41.557369Z","iopub.execute_input":"2025-06-20T16:11:41.557706Z","iopub.status.idle":"2025-06-20T16:18:14.148659Z","shell.execute_reply.started":"2025-06-20T16:11:41.557683Z","shell.execute_reply":"2025-06-20T16:18:14.147744Z"}},"outputs":[{"name":"stdout","text":"Processing 16055 SMILES... 1001/16055 2001/16055 3001/16055 4001/16055 5001/16055 6001/16055 7001/16055 8001/16055 9001/16055 10001/16055 11001/16055 12001/16055 13001/16055 14001/16055 15001/16055 16001/16055 16055/16055 ✅\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# Clean Train Data\n* Just replaces any NaNs with Median for the column\n* This function is also used to process Test data later","metadata":{}},{"cell_type":"code","source":"def clean_features(X):\n    \"\"\"Handle NaN/inf values and impute missing data\"\"\"\n    # Create a copy to avoid modifying the original\n    X_clean = X.copy()\n    \n    X_clean[np.isinf(X_clean)] = np.nan\n    \n    # Count and report missing values\n    missing = np.isnan(X_clean).sum()\n    print(f\"🧹 Cleaned {missing:,} missing values ({missing/X_clean.size*100:.1f}%)\")\n    \n    # Median imputation\n    for i in range(X_clean.shape[1]):\n        col = X_clean[:, i]\n        if np.isnan(col).any():\n            X_clean[np.isnan(col), i] = np.nanmedian(col) if not np.isnan(np.nanmedian(col)) else 0\n    \n    return X_clean\n\nX = clean_features(X_raw)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:18:14.151324Z","iopub.execute_input":"2025-06-20T16:18:14.151632Z","iopub.status.idle":"2025-06-20T16:18:14.232293Z","shell.execute_reply.started":"2025-06-20T16:18:14.151611Z","shell.execute_reply":"2025-06-20T16:18:14.231318Z"}},"outputs":[{"name":"stdout","text":"🧹 Cleaned 195,250 missing values (5.6%)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":" # Function to Train an LGBM model for a given target\n * Runs RDKit feature generation on SMILES data\n * Creates / trains a model for a specific target ('Tg', 'FFV', 'Tc', 'Density', 'Rg')\n * Uses 5x cross-validation to utilize all training data (5 models per feature)","metadata":{}},{"cell_type":"code","source":"def train_target_property(X_target, y_target):\n    print(f\"📊 Training on {len(y_target)} samples \")\n    print(f\"📈 Target range: {y_target.min():.4f} to {y_target.max():.4f}\")\n    \n    # Scale features\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(X_target)\n    \n    # LightGBM parameters\n    params = {\n        'objective': 'regression',\n        'metric': 'mae',\n        'boosting_type': 'gbdt',\n        'num_leaves': 127,           \n        'learning_rate': 0.07,       \n        'feature_fraction': 0.8,     \n        'bagging_fraction': 0.9,     \n        'bagging_freq': 1,           # Bag every iteration\n        'lambda_l1': 0.1,            # L1 regularization\n        'lambda_l2': 0.1,            # L2 regularization\n        'min_data_in_leaf': 10,      # Prevent overfitting\n        'verbose': -1,\n        'random_state': 42\n    }\n    \n    # 5-fold cross-validation\n    cv_scores = []\n    models = []\n    all_val_true = []\n    all_val_pred = []\n    \n    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n        y_train, y_val = y_target[train_idx], y_target[val_idx]\n        \n        train_data = lgb.Dataset(X_train, label=y_train)\n        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n        \n        model = lgb.train(\n            params,\n            train_data,\n            valid_sets=[val_data],\n            num_boost_round=2000,\n            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n        )\n        \n        val_pred = model.predict(X_val)\n        cv_score = mean_absolute_error(y_val, val_pred)\n        cv_scores.append(cv_score)\n        models.append(model)\n        \n        # Store for competition metric calculation\n        all_val_true.extend(y_val)\n        all_val_pred.extend(val_pred)\n        \n        print(f\"----Fold {fold+1} Complete / MAE = {cv_score:.4f}\", flush=True)\n    \n    cv_mean = np.mean(cv_scores)\n    print(f\"===CV: {cv_mean:.4f} ± {np.std(cv_scores):.3f}===\")\n    return models, scaler, cv_mean, all_val_true, all_val_pred","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:18:14.233293Z","iopub.execute_input":"2025-06-20T16:18:14.233559Z","iopub.status.idle":"2025-06-20T16:18:14.244727Z","shell.execute_reply.started":"2025-06-20T16:18:14.233534Z","shell.execute_reply":"2025-06-20T16:18:14.243437Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Training Loop\n* Loops through all 5 polymer target properties (Tg, FFV, Tc, Density, Rg)\n* Trains LGBM models for each target\n* 5x models per target trained using CV = **25 models total!**","metadata":{}},{"cell_type":"code","source":"# Store trained models and scalers\ntrained_models = {}\ntrained_scalers = {}\ncv_scores = []\n\n# Store all predictions for final competition score\nall_cv_predictions = {}\nall_cv_true = {}\n\n# Train each target\nfor target in targets:\n    print(f\"Training {target}...\")\n    \n    # Prepare training data for the current target\n    mask = train_df[target].notna()\n    X_target = X[mask]\n    y_target = train_df[target].values[mask]\n    \n    models, scaler, cv_score, val_true, val_pred = train_target_property(X_target, y_target)\n    trained_models[target] = models\n    trained_scalers[target] = scaler\n    cv_scores.append(cv_score)\n    \n    # Store for overall competition score\n    all_cv_true[target] = val_true\n    all_cv_predictions[target] = val_pred\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:18:14.245963Z","iopub.execute_input":"2025-06-20T16:18:14.246510Z","iopub.status.idle":"2025-06-20T16:20:40.837632Z","shell.execute_reply.started":"2025-06-20T16:18:14.246463Z","shell.execute_reply":"2025-06-20T16:20:40.836921Z"}},"outputs":[{"name":"stdout","text":"Training Tg...\n📊 Training on 7719 samples \n📈 Target range: -148.0297 to 495.0000\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[372]\tvalid_0's l1: 28.4018\n----Fold 1 Complete / MAE = 28.4018\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[191]\tvalid_0's l1: 28.1247\n----Fold 2 Complete / MAE = 28.1247\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[645]\tvalid_0's l1: 27.0196\n----Fold 3 Complete / MAE = 27.0196\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[408]\tvalid_0's l1: 26.8925\n----Fold 4 Complete / MAE = 26.8925\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[349]\tvalid_0's l1: 27.4798\n----Fold 5 Complete / MAE = 27.4798\n===CV: 27.5837 ± 0.595===\n\nTraining FFV...\n📊 Training on 7030 samples \n📈 Target range: 0.2270 to 0.7771\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[864]\tvalid_0's l1: 0.00710976\n----Fold 1 Complete / MAE = 0.0071\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[2000]\tvalid_0's l1: 0.0065742\n----Fold 2 Complete / MAE = 0.0066\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[1742]\tvalid_0's l1: 0.00653813\n----Fold 3 Complete / MAE = 0.0065\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[1930]\tvalid_0's l1: 0.00627904\n----Fold 4 Complete / MAE = 0.0063\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[1421]\tvalid_0's l1: 0.006934\n----Fold 5 Complete / MAE = 0.0069\n===CV: 0.0067 ± 0.000===\n\nTraining Tc...\n📊 Training on 1611 samples \n📈 Target range: 0.0465 to 1.5900\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1997]\tvalid_0's l1: 0.0129374\n----Fold 1 Complete / MAE = 0.0129\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1982]\tvalid_0's l1: 0.0145166\n----Fold 2 Complete / MAE = 0.0145\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[267]\tvalid_0's l1: 0.0189901\n----Fold 3 Complete / MAE = 0.0190\nTraining until validation scores don't improve for 50 rounds\nDid not meet early stopping. Best iteration is:\n[1997]\tvalid_0's l1: 0.0171409\n----Fold 4 Complete / MAE = 0.0171\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[1376]\tvalid_0's l1: 0.0146364\n----Fold 5 Complete / MAE = 0.0146\n===CV: 0.0156 ± 0.002===\n\nTraining Density...\n📊 Training on 613 samples \n📈 Target range: 0.7487 to 1.8410\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[185]\tvalid_0's l1: 0.0327763\n----Fold 1 Complete / MAE = 0.0328\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[238]\tvalid_0's l1: 0.0511025\n----Fold 2 Complete / MAE = 0.0511\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[315]\tvalid_0's l1: 0.0280548\n----Fold 3 Complete / MAE = 0.0281\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[116]\tvalid_0's l1: 0.0232483\n----Fold 4 Complete / MAE = 0.0232\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[274]\tvalid_0's l1: 0.0322546\n----Fold 5 Complete / MAE = 0.0323\n===CV: 0.0335 ± 0.009===\n\nTraining Rg...\n📊 Training on 614 samples \n📈 Target range: 9.7284 to 34.6729\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[74]\tvalid_0's l1: 2.04216\n----Fold 1 Complete / MAE = 2.0422\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[66]\tvalid_0's l1: 1.97609\n----Fold 2 Complete / MAE = 1.9761\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[103]\tvalid_0's l1: 1.92493\n----Fold 3 Complete / MAE = 1.9249\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[82]\tvalid_0's l1: 1.64126\n----Fold 4 Complete / MAE = 1.6413\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[122]\tvalid_0's l1: 1.76517\n----Fold 5 Complete / MAE = 1.7652\n===CV: 1.8699 ± 0.146===\n\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Estimate LB Score\n* Use the competition metric to estimate LB across all targets\n* As mentioned earlier - **probably optimistic** since we choose boosting round (epoch) based on best score\n* Import https://www.kaggle.com/code/richolson/open-polymer-2025-metric which is a copy of https://www.kaggle.com/code/metric/open-polymer-2025","metadata":{}},{"cell_type":"code","source":"# Import the competition metric\nimport open_polymer_2025_metric as metric\n\n# Create DataFrames for final competition score calculation\ncv_true_df = pd.DataFrame()\ncv_pred_df = pd.DataFrame()\n\nfor target in targets:\n    # Pad shorter arrays with NULL_FOR_SUBMISSION to make them same length\n    max_len = max(len(all_cv_true[t]) for t in targets)\n    \n    true_padded = list(all_cv_true[target]) + [metric.NULL_FOR_SUBMISSION] * (max_len - len(all_cv_true[target]))\n    pred_padded = list(all_cv_predictions[target]) + [metric.NULL_FOR_SUBMISSION] * (max_len - len(all_cv_predictions[target]))\n    \n    cv_true_df[target] = true_padded\n    cv_pred_df[target] = pred_padded\n\n# Add dummy id column\ncv_true_df['id'] = range(len(cv_true_df))\ncv_pred_df['id'] = range(len(cv_pred_df))\n\n# Calculate individual competition scores\ncompetition_scores = []\nfor target in targets:\n    comp_score = metric.scaling_error(np.array(all_cv_true[target]), np.array(all_cv_predictions[target]), target)\n    competition_scores.append(comp_score)\n\n# Calculate overall competition score\nestimated_lb_score = metric.score(cv_true_df, cv_pred_df, 'id')\n\nprint(\"=\" * 50)\nprint(f\"Trained: {len(targets)} targets × 5 CV folds = {len(targets) * 5} models\")\nprint(f\"Average CV MAE across all targets: {np.mean(cv_scores):.4f}\")\nprint(f\"Individual competition scores: {[f'{s:.4f}' for s in competition_scores]}\")\nprint(f\"🎯 ESTIMATED LB SCORE: {estimated_lb_score:.4f}\")\nprint(\"=\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:20:40.839157Z","iopub.execute_input":"2025-06-20T16:20:40.839480Z","iopub.status.idle":"2025-06-20T16:20:40.903616Z","shell.execute_reply.started":"2025-06-20T16:20:40.839458Z","shell.execute_reply":"2025-06-20T16:20:40.902691Z"}},"outputs":[{"name":"stdout","text":"==================================================\nTrained: 5 targets × 5 CV folds = 25 models\nAverage CV MAE across all targets: 5.9019\nIndividual competition scores: ['0.0445', '0.0122', '0.0328', '0.0307', '0.0750']\n🎯 ESTIMATED LB SCORE: 0.0444\n==================================================\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Function to Predict using trained LGBM models for a given target\n* Runs same RDKit feature generation on test SMILES data\n* Uses the 5 trained models to predict a specific target\n* Averages predictions from all 5 models for final result","metadata":{}},{"cell_type":"code","source":"def predict_target_property(test_df, target_name, models, scaler):\n    \n    print(f\"PREDICTING: {target_name}\")\n    \n    if models is None or scaler is None:\n        print(f\"❌ No trained model available for {target_name}, returning zeros\")\n        return np.zeros(len(test_df))\n    \n    # Get molecular features - step by step\n    descriptor_functions, _ = molecular_descriptors\n    X_raw = smiles_to_features(test_df['SMILES'].values, descriptor_functions)\n    X = clean_features(X_raw)\n    \n    # Scale features using same scaler from training\n    X_scaled = scaler.transform(X)\n    \n    # Average predictions from all CV folds\n    fold_predictions = []\n    for model in models:\n        pred = model.predict(X_scaled)\n        fold_predictions.append(pred)\n    \n    predictions = np.mean(fold_predictions, axis=0)\n    print(f\"📊 Predictions range: {predictions.min():.4f} to {predictions.max():.4f}\")\n    \n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:20:40.904616Z","iopub.execute_input":"2025-06-20T16:20:40.904930Z","iopub.status.idle":"2025-06-20T16:20:40.912189Z","shell.execute_reply.started":"2025-06-20T16:20:40.904902Z","shell.execute_reply":"2025-06-20T16:20:40.911299Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# Predict All Targets / Submit\n* Predict on test data\n* Creates final submission CSV with all predictions","metadata":{}},{"cell_type":"code","source":"# Load test data\ntest_df = pd.read_csv('/kaggle/input/neurips-open-polymer-prediction-2025/test.csv')\n\nprint(f\"\\nMAKING PREDICTIONS...\")\nall_predictions = {}\nfor target in targets:\n    predictions = predict_target_property(\n        test_df, target, trained_models[target], trained_scalers[target]\n    )\n    all_predictions[target] = predictions\n\n# Create submission\nsubmission = pd.DataFrame({'id': test_df['id']})\nfor target in targets:\n    submission[target] = all_predictions[target]\n\nsubmission.to_csv('submission.csv', index=False)\n\nprint(f\"Predicted: {len(test_df)} test samples\")\nprint(f\"Saved: submission.csv\")\n\nprint(f\"\\n👀 SUBMISSION PREVIEW:\")\nprint(submission.head().to_string(index=False, float_format='%.4f'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-20T16:20:40.913180Z","iopub.execute_input":"2025-06-20T16:20:40.913433Z","iopub.status.idle":"2025-06-20T16:20:41.502474Z","shell.execute_reply.started":"2025-06-20T16:20:40.913413Z","shell.execute_reply":"2025-06-20T16:20:41.501518Z"}},"outputs":[{"name":"stdout","text":"\nMAKING PREDICTIONS...\nPREDICTING: Tg\nProcessing 3 SMILES... 3/3 ✅\n🧹 Cleaned 37 missing values (5.7%)\n📊 Predictions range: 140.0810 to 155.1468\nPREDICTING: FFV\nProcessing 3 SMILES... 3/3 ✅\n🧹 Cleaned 37 missing values (5.7%)\n📊 Predictions range: 0.3504 to 0.3778\nPREDICTING: Tc\nProcessing 3 SMILES... 3/3 ✅\n🧹 Cleaned 37 missing values (5.7%)\n📊 Predictions range: 0.1683 to 0.2554\nPREDICTING: Density\nProcessing 3 SMILES... 3/3 ✅\n🧹 Cleaned 37 missing values (5.7%)\n📊 Predictions range: 1.0848 to 1.1699\nPREDICTING: Rg\nProcessing 3 SMILES... 3/3 ✅\n🧹 Cleaned 37 missing values (5.7%)\n📊 Predictions range: 19.9183 to 20.3570\nPredicted: 3 test samples\nSaved: submission.csv\n\n👀 SUBMISSION PREVIEW:\n        id       Tg    FFV     Tc  Density      Rg\n1109053969 153.4488 0.3754 0.1683   1.1699 19.9183\n1422188626 155.1468 0.3778 0.2307   1.0848 20.0204\n2032016830 140.0810 0.3504 0.2554   1.0999 20.3570\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"Result:\n\nScore: 0.059\n\nRank: 66 (2025-0621-1:47, JST)\n\nYour First Entry!\nWelcome to the leaderboard!","metadata":{}}]}